{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14010596,"sourceType":"datasetVersion","datasetId":8925232}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom scipy.stats import skew, kurtosis \nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import linregress\nimport gc\n\nBASE_PATH = '/kaggle/input/mallorn-dataset'\nSEQ_LEN = 150        \nBATCH_SIZE = 64      \nNUM_EPOCHS = 30   \nLEARNING_RATE = 1e-5\nVAL_SIZE = 0.2\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef extract_features(fluxes, times, flux_errs, filters):\n    if len(fluxes) == 0: \n        return [0]*10\n    f = fluxes\n    t = times\n    fil = np.array(filters)\n    max_f = np.max(f)\n    min_f = np.min(f)\n    mean = np.mean(f) \n    std = np.std(f)\n    sk = skew(f) if std > 0 else 0 \n    kt = kurtosis(f) if std > 0 else 0\n    amplitude = (np.max(f) - np.min(f)) / 2\n\n    flux_by_band = {b: [] for b in range(6)}\n    for val, band in zip(f, filters):\n        flux_by_band[band].append(val)\n        \n    means_band = {b: np.mean(vals) if len(vals)>0 else np.nan for b, vals in flux_by_band.items()}\n    \n    u_g = np.nan_to_num(means_band[0] - means_band[1]) \n    g_r = np.nan_to_num(means_band[1] - means_band[2]) \n    r_i = np.nan_to_num(means_band[2] - means_band[3]) \n    \n    flux_ratio = max_f / (np.abs(np.median(f)) + 1e-6)\n    \n    idx_max = np.argmax(f)\n    time_max = t[idx_max]\n    slope = 0\n    if idx_max < len(f) - 1:\n        decay_flux = f[idx_max:]\n        decay_time = t[idx_max:]\n        if len(np.unique(decay_time)) > 1:\n            try:\n                slope, _, _, _, _ = linregress(decay_time, decay_flux)\n                if np.isnan(slope): slope = 0\n            except ValueError:\n                slope = 0 \n        else:\n            slope = 0\n\n    n = len(f)\n    if n > 1 and std > 0:\n        residuals = (f - mean) / (std + 1e-6)\n        stetson_k = (1 / np.sqrt(n)) * np.sum(np.abs(residuals)) / np.sqrt(np.mean(residuals**2))\n    else:\n        stetson_k = 0\n    t_peak = t[idx_max]\n    t_rise = t_peak - t[0]\n    t_decay = t[-1] - t_peak\n    rise_decay_ratio = 0\n    if t_decay > 0:\n        rise_decay_ratio = t_rise / (t_decay + 1e-6)\n\n    power_law_index = 0\n    \n    if idx_max < n - 2: \n        post_peak_f = f[idx_max+1:]\n        post_peak_t = t[idx_max+1:]\n        valid_mask = post_peak_f > 0\n        if np.sum(valid_mask) > 1: \n            y_log = np.log(post_peak_f[valid_mask])\n            x_log = np.log(post_peak_t[valid_mask] - t_peak + 1.0) \n            if len(np.unique(x_log)) > 1:\n                try:\n                    p_index, _, _, _, _ = linregress(x_log, y_log)\n                    if not np.isnan(p_index):\n                        power_law_index = p_index\n                except: power_law_index = 0\n    \n    mask_peak = (t <= t_peak + 10)\n    mask_tail = (t > t_peak + 20)\n    def get_color_gr(mask):\n        f_masked = f[mask]\n        fil_masked = fil[mask]\n        g_vals = f_masked[fil_masked == 1] \n        r_vals = f_masked[fil_masked == 2] \n        if len(g_vals) > 0 and len(r_vals) > 0:\n            return np.mean(g_vals) - np.mean(r_vals)\n        return 0.0 \n    gr_peak = get_color_gr(mask_peak)\n    gr_tail = get_color_gr(mask_tail)\n    \n    delta_color_gr = gr_tail - gr_peak if gr_tail != 0 and gr_peak != 0 else 0\n    half_max_flux = max_f / 2.0\n    width_half_max = 0\n\n    mask_high = f > half_max_flux\n    if np.sum(mask_high) >= 2:\n        t_high = t[mask_high]\n        width_half_max = t_high.max() - t_high.min()\n    else:\n        width_half_max = 0\n        \n    t_rise_50 = t_peak - t[f > half_max_flux].min() if np.sum(f > half_max_flux) > 0 else 0\n    t_fall_50 = t[f > half_max_flux].max() - t_peak if np.sum(f > half_max_flux) > 0 else 0\n    \n    asymmetry_50 = t_fall_50 / (t_rise_50 + 1e-6)\n    \n    return [mean, std, sk, kt, amplitude, \n            u_g, g_r, r_i, flux_ratio, len(f),\n            means_band[0], means_band[1], means_band[2], slope, stetson_k,\n            rise_decay_ratio, power_law_index, delta_color_gr, width_half_max, asymmetry_50]\n\n\ndf_log = pd.read_csv('/kaggle/input/mallorn-dataset/train_log.csv')\nTRAIN_Z_MAX = df_log['Z'].max()\nTRAIN_EBV_MAX = df_log['EBV'].max()\ndf_log['Z'] = df_log['Z'] / (df_log['Z'].max() + 1e-6)\ndf_log['EBV'] = df_log['EBV'] / (df_log['EBV'].max() + 1e-6)\n\nlabel_encoder = LabelEncoder()\ndf_log['label_encoded'] = label_encoder.fit_transform(df_log['SpecType'])\nnum_classes = len(label_encoder.classes_)\ntde_index = label_encoder.transform(['TDE'])[0]\n\nclass_weights = torch.ones(num_classes, dtype=torch.float32).to(device)\n\nclass_weights[tde_index] = 5\n\n\nstatic_dict = df_log.set_index('object_id')[['Z', 'EBV']].T.to_dict('list')\nid_to_label = dict(zip(df_log['object_id'], df_log['label_encoded']))\n\nall_X_seq = []   \nall_X_static = [] \nall_y = []\nband_map = {'u': 0, 'g': 1, 'r': 2, 'i': 3, 'z': 4, 'y': 5}\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n        \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n        \n        pt = torch.exp(-ce_loss)\n        \n        focal_loss = (1 - pt) ** self.gamma * ce_loss\n\n        if self.reduction == 'mean':\n            return torch.mean(focal_loss)\n        elif self.reduction == 'sum':\n            return torch.sum(focal_loss)\n        else:\n            return focal_loss\n            \nfor i in range(1, 21): \n    folder_name = f\"split_{i:02d}\"\n    file_path = f\"{BASE_PATH}/{folder_name}/train_full_lightcurves.csv\"\n    df_chunk = pd.read_csv(file_path, usecols=['object_id', 'Flux', 'Time (MJD)', 'Flux_err', 'Filter'], dtype={'Flux': 'float32', 'Time (MJD)': 'float32'})\n    grouped = df_chunk.groupby('object_id').agg({'Flux': list, 'Time (MJD)': list, 'Flux_err': list, 'Filter': list}).to_dict(orient='index')\n    \n    for obj_id, data in grouped.items():\n        fluxes = np.array(data['Flux'], dtype=np.float32)\n        times = np.array(data['Time (MJD)'], dtype=np.float32)\n        filters = np.array([band_map.get(f, 0) for f in data['Filter']])\n        flux_errs = np.array(data['Flux_err'], dtype=np.float32)\n        \n        sorted_idx = np.argsort(times)\n        times = times[sorted_idx]\n        fluxes = fluxes[sorted_idx]\n        flux_errs = flux_errs[sorted_idx]\n        filters = filters[sorted_idx]\n        \n        phys_feats = extract_features(fluxes, times, flux_errs, filters)\n        \n        f_mean = np.mean(fluxes)\n        f_std = np.std(fluxes) + 1e-6\n        fluxes = (fluxes - f_mean) / f_std\n        fluxes = fluxes.tolist()\n        \n        flux_errs = flux_errs / f_std\n        flux_errs = flux_errs.tolist()\n        \n        start_time = times[0]\n        norm_times = times - start_time\n        norm_times = norm_times.tolist()\n\n        filters = filters.tolist()\n\n        if len(fluxes) > SEQ_LEN:\n            fluxes = fluxes[:SEQ_LEN]\n            norm_times = norm_times[:SEQ_LEN]\n            flux_errs = flux_errs[:SEQ_LEN]\n            filters = filters[:SEQ_LEN]\n        else:\n            pad_len = SEQ_LEN - len(fluxes)\n            fluxes = fluxes + [0.0] * pad_len\n            norm_times = norm_times + [0.0] * pad_len\n            flux_errs = flux_errs + [0.0] * pad_len \n            filters = filters + [0] * pad_len\n            \n        combined_seq = [[f, t, err, filt] for f, t, err, filt in zip(fluxes, norm_times, flux_errs, filters)]\n        current_static = static_dict[obj_id] + phys_feats\n        \n        all_X_seq.append(combined_seq)\n        all_X_static.append(current_static)\n        all_y.append(id_to_label[obj_id])\n        \n    del df_chunk, grouped\n    gc.collect()\n\nX_seq_tensor = torch.tensor(all_X_seq, dtype=torch.float32)\nX_seq_tensor = torch.nan_to_num(X_seq_tensor, nan=0.0)\n\nX_static_tensor = torch.tensor(all_X_static, dtype=torch.float32)\nX_static_tensor = torch.nan_to_num(X_static_tensor, nan=0.0)\n\nmean_static = X_static_tensor.mean(dim=0)\nstd_static = X_static_tensor.std(dim=0) + 1e-6\nX_static_tensor = (X_static_tensor - mean_static) / std_static\n\ny_tensor = torch.tensor(all_y, dtype=torch.long)\n\nSTATIC_INPUT_DIM = X_static_tensor.shape[1] \n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=500): \n        super(PositionalEncoding, self).__init__()\n        \n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        \n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1), :]\n        return x\n\nclass Transformer(nn.Module):\n    def __init__(self, seq_len, static_input_dim, d_model, num_classes):\n        super(Transformer, self).__init__()\n        self.filter_embedding = nn.Embedding(num_embeddings=6, embedding_dim=16)\n        \n        total_input_dim = 3 + 16 + static_input_dim \n        self.input_proj = nn.Linear(total_input_dim, d_model)\n        self.pos_encoder = PositionalEncoding(d_model, max_len=seq_len + 50)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model = d_model,\n            nhead = 4,\n            dim_feedforward=256,\n            batch_first=True,\n            dropout = 0.3\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers = 4)\n        \n        self.fc = nn.Sequential(\n            nn.Linear(d_model, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x_seq, x_static):\n        batch_size, seq_len, _ = x_seq.shape\n        \n        numeric_feats = x_seq[:, :, :3]\n        filter_ids = x_seq[:, :, 3].long()\n        filter_emb = self.filter_embedding(filter_ids)\n        \n        padding_mask = (numeric_feats[:, :, 0] != 0).float().unsqueeze(-1)\n        \n        static_expanded = x_static.unsqueeze(1).repeat(1, seq_len, 1)\n        static_expanded = static_expanded * padding_mask\n        \n        combined_input = torch.cat([numeric_feats, filter_emb, static_expanded], dim=-1)\n        \n        x = self.input_proj(combined_input)\n        \n        src_key_padding_mask = (numeric_feats[:, :, 0] == 0)\n        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n        \n        x = torch.nan_to_num(x, nan=0.0)\n        x_max = x.max(dim=1)[0]\n        x_mean = x.mean(dim=1)\n        x_feat = x_max + x_mean\n        \n        res = self.fc(x_feat)\n        return res\n\nclass LSTMModel(nn.Module):\n    def __init__(self, static_input_dim, hidden_dim, num_classes, num_layers=2):\n        super(LSTMModel, self).__init__()\n        \n        self.filter_embedding = nn.Embedding(num_embeddings=6, embedding_dim=16)\n        \n        input_dim = 3 + 16 \n        \n        self.lstm = nn.LSTM(\n            input_size=input_dim, \n            hidden_size=hidden_dim, \n            num_layers=num_layers, \n            batch_first=True, \n            bidirectional=True,\n            dropout=0.3\n        )\n        \n        self.static_proj = nn.Sequential(\n            nn.Linear(static_input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.2)\n        )\n        \n        combined_dim = (hidden_dim * 4) + hidden_dim\n        \n        self.fc = nn.Sequential(\n            nn.Linear(combined_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x_seq, x_static):\n        numeric_feats = x_seq[:, :, :3]\n        filter_ids = x_seq[:, :, 3].long()\n        filter_emb = self.filter_embedding(filter_ids)\n        lstm_input = torch.cat([numeric_feats, filter_emb], dim=-1)\n        out, _ = self.lstm(lstm_input)\n        \n        avg_pool = torch.mean(out, dim=1)\n        max_pool, _ = torch.max(out, dim=1)\n        seq_feat = torch.cat([avg_pool, max_pool], dim=1) \n        \n        static_feat = self.static_proj(x_static) \n        \n        final_feat = torch.cat([seq_feat, static_feat], dim=1)\n        return self.fc(final_feat)\n        \nN_FOLDS = 4\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\nfold_best_thresholds = []\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X_seq_tensor, y_tensor.cpu().numpy())):\n    print(f\"\\n{'='*20} FOLD {fold+1}/{N_FOLDS} {'='*20}\")\n\n    X_seq_train_fold = X_seq_tensor[train_idx]\n    X_static_train_fold = X_static_tensor[train_idx]\n    y_train_fold = y_tensor[train_idx]\n    \n    X_seq_val_fold = X_seq_tensor[val_idx]\n    X_static_val_fold = X_static_tensor[val_idx]\n    y_val_fold = y_tensor[val_idx]\n\n    train_ds = torch.utils.data.TensorDataset(X_seq_train_fold, X_static_train_fold, y_train_fold)\n    val_ds = torch.utils.data.TensorDataset(X_seq_val_fold, X_static_val_fold, y_val_fold)\n    \n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n\n    model = LSTMModel(\n        static_input_dim=STATIC_INPUT_DIM,\n        hidden_dim=128,      \n        num_classes=num_classes,\n        num_layers=2         \n    ).to(device)\n    \n    criterion = FocalLoss(alpha=class_weights, gamma=2.0).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4) \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n    fold_best_f1 = 0.0\n    fold_best_thr = 0.5\n    \n    for epoch in range(NUM_EPOCHS):\n        model.train()\n        total_loss = 0\n        \n        for batch_seq, batch_static, batch_y in train_loader:\n            batch_seq, batch_static, batch_y = batch_seq.to(device), batch_static.to(device), batch_y.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(batch_seq, batch_static)\n            loss = criterion(outputs, batch_y)\n            \n            if torch.isnan(loss): continue\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n        avg_train_loss = total_loss / len(train_loader)\n        model.eval()\n        val_loss = 0\n        all_probs = []   \n        all_targets = []\n        with torch.no_grad():\n            for batch_seq, batch_static, batch_y in val_loader:\n                batch_seq, batch_static, batch_y = batch_seq.to(device), batch_static.to(device), batch_y.to(device)\n                \n                outputs = model(batch_seq, batch_static)\n                loss = criterion(outputs, batch_y)\n                val_loss += loss.item()\n                \n                probs = torch.softmax(outputs, dim=1)[:, tde_index]\n                \n                all_probs.extend(probs.cpu().numpy())\n                all_targets.extend((batch_y == tde_index).cpu().numpy().astype(int))\n        avg_val_loss = val_loss / len(val_loader)\n        scheduler.step(avg_val_loss)\n        print(f\"\\nEpoch [{epoch+1}/{NUM_EPOCHS}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")       \n        thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n        \n        all_probs = np.array(all_probs)\n        all_targets = np.array(all_targets)\n        \n        epoch_best_f1 = 0\n        epoch_best_thr = 0\n        for thr in thresholds:\n            preds = (all_probs > thr).astype(int)\n            f1 = f1_score(all_targets, preds, zero_division=0)\n            if f1 > epoch_best_f1:\n                epoch_best_f1 = f1\n                epoch_best_thr = thr\n        print(f\"   >>> Epoch Best F1: {epoch_best_f1:.4f} at Thr: {epoch_best_thr}\")\n        if epoch_best_f1 > fold_best_f1 and epoch > 20:\n            fold_best_f1 = epoch_best_f1\n            fold_best_thr = epoch_best_thr\n            \n            save_name = f'best_model_fold_{fold}.pth'\n            \n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'threshold': fold_best_thr,\n                'f1_score': fold_best_f1\n            }, save_name)\n            \n            print(f\"   >>> [SAVED] New Best Model for Fold {fold} (F1: {fold_best_f1:.4f})\")\n            \n    print(f\"--- Finished Fold {fold+1}. Best F1: {fold_best_f1:.4f} at Threshold: {fold_best_thr} ---\")\n    fold_best_thresholds.append(fold_best_thr)\n    del model, optimizer, train_loader, val_loader, train_ds, val_ds\n    torch.cuda.empty_cache()\n    gc.collect()\n\nprint(\"Best Thresholds per fold:\", fold_best_thresholds)\nnp.save('folds_thresholds.npy', np.array(fold_best_thresholds))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom scipy.stats import skew, kurtosis\nimport gc\n\n\nBASE_PATH = '/kaggle/input/mallorn-dataset'\nSEQ_LEN = 150        \nBATCH_SIZE_TEST = 128      \nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nFINAL_THRESHOLD = 0.35\n\n\ndf_train_full = pd.read_csv(f'{BASE_PATH}/train_log.csv')\nunique_labels = sorted(df_train_full['SpecType'].unique())\nnum_classes = len(unique_labels)\n\n\nTRAIN_Z_MAX = df_train_full['Z'].max()\nTRAIN_EBV_MAX = df_train_full['EBV'].max()\nstatic_dict_train = df_train_full.set_index('object_id')[['Z', 'EBV']].T.to_dict('list')\n\ndf_test_log = pd.read_csv(f'{BASE_PATH}/test_log.csv')\ndf_test_log['Z'] = df_test_log['Z'] / (TRAIN_Z_MAX + 1e-6)\ndf_test_log['EBV'] = df_test_log['EBV'] / (TRAIN_EBV_MAX + 1e-6)\nstatic_dict_test = df_test_log.set_index('object_id')[['Z', 'EBV']].T.to_dict('list')\n\nmodels = []\nfor fold in range(4):\n    model = LSTMModel(\n        static_input_dim=STATIC_INPUT_DIM,\n        hidden_dim=128,      \n        num_classes=num_classes,\n        num_layers=2         \n    ).to(device)\n    checkpoint = torch.load(f'best_model_fold_{fold}.pth', map_location=DEVICE)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    models.append(model)\n\nresults = {}\nmean_static = mean_static.to(DEVICE)\nstd_static = std_static.to(DEVICE)\nwith torch.no_grad(): \n    for i in range(1, 21): \n        folder_name = f\"split_{i:02d}\"\n        file_path = f\"{BASE_PATH}/{folder_name}/test_full_lightcurves.csv\"\n        df_chunk = pd.read_csv(file_path, usecols=['object_id', 'Flux', 'Time (MJD)', 'Flux_err', 'Filter'], \n                               dtype={'Flux': 'float32', 'Time (MJD)': 'float32'})\n        \n        grouped = df_chunk.groupby('object_id').agg({\n            'Flux': list, 'Time (MJD)': list, 'Flux_err': list, 'Filter': list\n        }).to_dict(orient='index')\n        \n        batch_ids, batch_seq, batch_static = [], [], []\n        \n        for obj_id, data in grouped.items():\n            fluxes = np.array(data['Flux'], dtype=np.float32)\n            times = np.array(data['Time (MJD)'], dtype=np.float32)\n            flux_errs = np.array(data['Flux_err'], dtype=np.float32)\n            filters = np.array([band_map.get(f, 0) for f in data['Filter']])\n\n            sorted_idx = np.argsort(times)\n            times = times[sorted_idx]\n            fluxes = fluxes[sorted_idx]\n            flux_errs = flux_errs[sorted_idx]\n            filters = filters[sorted_idx]\n            \n            phys_feats = extract_features(fluxes, times, flux_errs, filters)\n            \n            f_std = np.std(fluxes) + 1e-6\n            fluxes = ((fluxes - np.mean(fluxes)) / f_std).tolist()\n            flux_errs = (flux_errs / f_std).tolist()\n            norm_times = (times - times[0]).tolist()\n            filters = filters.tolist()\n            \n            if len(fluxes) > SEQ_LEN:\n                fluxes, norm_times, flux_errs, filters = fluxes[:SEQ_LEN], norm_times[:SEQ_LEN], flux_errs[:SEQ_LEN], filters[:SEQ_LEN]\n            else:\n                pad = SEQ_LEN - len(fluxes)\n                fluxes += [0]*pad; norm_times += [0]*pad; flux_errs += [0]*pad; filters += [0]*pad\n            \n            batch_ids.append(obj_id)\n            batch_seq.append([[f, t, err, filt] for f, t, err, filt in zip(fluxes, norm_times, flux_errs, filters)])\n            batch_static.append(static_dict_test[obj_id] + phys_feats)\n            \n            if len(batch_ids) >= BATCH_SIZE_TEST:\n                X_seq = torch.tensor(batch_seq, dtype=torch.float32).to(DEVICE)\n                X_stat = torch.tensor(batch_static, dtype=torch.float32).to(DEVICE)\n                \n                X_seq = torch.nan_to_num(X_seq, nan=0.0)\n                X_stat = torch.nan_to_num(X_stat, nan=0.0)\n                X_stat = (X_stat - mean_static) / std_static\n                X_stat = torch.nan_to_num(X_stat, nan=0.0) \n                \n                avg_probs = np.zeros(len(batch_ids))\n                for model in models:\n                    avg_probs += torch.softmax(model(X_seq, X_stat), dim=1)[:, tde_index].cpu().numpy()\n                avg_probs /= len(models)\n                \n                preds = (avg_probs > FINAL_THRESHOLD).astype(int)\n                for oid, p in zip(batch_ids, preds): results[oid] = p\n                batch_ids, batch_seq, batch_static = [], [], []\n\n        if len(batch_ids) > 0:\n            X_seq = torch.tensor(batch_seq, dtype=torch.float32).to(DEVICE)\n            X_stat = torch.tensor(batch_static, dtype=torch.float32).to(DEVICE)\n            X_seq = torch.nan_to_num(X_seq, nan=0.0)\n            X_stat = torch.nan_to_num(X_stat, nan=0.0)\n            X_stat = (X_stat - mean_static) / std_static\n            X_stat = torch.nan_to_num(X_stat, nan=0.0)\n            \n            avg_probs = np.zeros(len(batch_ids))\n            for model in models:\n                avg_probs += torch.softmax(model(X_seq, X_stat), dim=1)[:, tde_index].cpu().numpy()\n            avg_probs /= len(models)\n            preds = (avg_probs > FINAL_THRESHOLD).astype(int)\n            for oid, p in zip(batch_ids, preds): \n                results[oid] = p\n        \n        del df_chunk, grouped\n        gc.collect()\n\n\nsubmission_df = pd.DataFrame({'object_id': df_test_log['object_id']})\nsubmission_df['prediction'] = submission_df['object_id'].map(results).fillna(0).astype(int)\nn_pos = submission_df['prediction'].sum()\nprint(f\" Tìm thấy {n_pos} TDE trên tổng số {len(submission_df)} mẫu.\")\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}